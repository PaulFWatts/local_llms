# local_llms
Local LLMs via Ollama & LM Studio - The Practical Guide
https://www.udemy.com/course/running-open-llms-locally-practical-guide

A Udemy course by [Maximilian Schwarzm√ºller](https://www.udemy.com/user/maximilian-schwarzmuller/)

Run open large language models like Gemma, Llama or DeepSeek locally to perform AI inference on consumer hardware.
